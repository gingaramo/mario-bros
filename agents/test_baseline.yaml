device: cpu

env:
  env_name: ALE/Pong-v5
  env_action_labels: [NOOP, FIRE, RIGHT, LEFT, RIGHTFIRE, LEFTFIRE]
  num_episodes: 500
  max_steps_per_episode: 5000
  use_score: false

agent:
  name: test_baseline
  # Minimal agent settings for baseline
  gamma: 0.99
  epsilon: 1.0
  epsilon_min: 0.02
  epsilon_decay: 0.995
  learning_rate: 0.0001
  batch_size: 16
  memory_size: 10000
  min_memory_size: 5000
  memory_selection: prioritized
  memory_selection_alpha: 0.7 # PER paper "sweet spot"
  memory_selection_beta: 0.5  # PER paper "sweet spot"
  loss: smooth_l1
  clip_gradients: 0.15
  optimizer: adam
  action_selection: softmax
  action_selection_temperature: 0.1

  # Action parameters
  action_repeat_steps: 0 # environment already skips 4 frames
  replay_every_n_steps: 4
  target_update_frequency: 2048


  state:
    resize_shape: [128, 128]
    grayscale: true
    normalize: true
    stack_frames: 4

  network:
    dqn:
      hidden_layers: [256]

